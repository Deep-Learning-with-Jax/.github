## Introduction to deep learning
This fifteen-day crash course is part of the course program for incoming Ph.D. students at the University of Bonn's [BIGS-Neuroscience](https://bigs-neuroscience.de/) and [BIGS Clinical and Population Science](https://bigs-clinpopscience.de/). We are releasing it here for those who could not attend the course in person. Furthermore, we hope that it will help a broader audience.

The material currently consists of lecture videos, slides and exercises.
Most exercises come with unit tests, allowing you to verify your solutions independently. The first exercise explains how to do that.

All exercises will run on Ubuntu 22.04.1 with ffmpeg version 4.4.2.

An extended version of this course is held in person every semester. [Members of the University can register](https://www.hpc.uni-bonn.de/en/training/courses/ml_intro).


Prerequisites:
Programming in Python. If you are unfamiliar with Python, please consult https://docs.python.org/3/tutorial/ before the first session.
University-level math courses make it much easier to understand the material. However, participants from our Humanities departments have completed the course in person.
## Course contents:

### Part 1, Basics
- Day 1: Introduction
    - What is machine learning, and what can it do for us?
- Day 2: Optimization
    - The derivative, gradients, optimization via gradient descent.
- Day 3:   Linear Algebra:
   - Matrix multiplication, singular value decomposition, Linear Regression.
- Day 4:  Statistics
   - Mean and variance, correlation, Gaussians.

### Part 2, Deep Learning
- Day 11: Fully connected networks:
    -  The MNIST-data set, artificial neurons, forward and backward pass.
- Day 12: Convolutional neural networks:
    -  The convolution operation and convolutional neural networks.
- Day 13: Optimization for deep neural networks:
    -  Gradient descent with momentum, Adam, early stopping, regularization.
- Day 14: Interpretability:
    - Visualization of linear classifiers, saliency maps, integrated gradients
 - Day 15: Sequence models:
    - Long-Short-Term-Memory, Gated recurrent units, text-based language models.


## Support

We thank the state of North Rhine-Westphalia and the Federal Ministry of Education and Research for supporting this project.

<table>
<tr>
    <td><img src="https://github.com/Machine-Learning-Foundations/.github/blob/main/profile/img/nrw-logo.png" height="150"></td>
    <td><img src="https://github.com/Machine-Learning-Foundations/.github/blob/main/profile/img/BMBF_gefoerdert_2017_en.jpg" height="150"></td>
</tr>
</table>
